{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c561ae70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Score Achieved: 92\n",
      "Employees eligible for Top Performance Bonus: Ravi, Kiran\n"
     ]
    }
   ],
   "source": [
    "#Problem Statement 1: Employee Performance Bonus Eligibility\n",
    "\n",
    "# 1. Input dictionary of employees and scores\n",
    "employees = {\n",
    "    \"Ravi\": 92,\n",
    "    \"Anita\": 88,\n",
    "    \"Kiran\": 92,\n",
    "    \"Suresh\": 85\n",
    "}\n",
    "\n",
    "# 2. Identify the highest performance score\n",
    "# We use max() on the dictionary values\n",
    "highest_score = max(employees.values())\n",
    "\n",
    "# 3. Handle ties: find all employees with the highest score\n",
    "# We use a list comprehension to filter the names\n",
    "eligible_employees = [name for name, score in employees.items() if score == highest_score]\n",
    "\n",
    "# 4. Display the results\n",
    "print(f\"Highest Score Achieved: {highest_score}\")\n",
    "print(f\"Employees eligible for Top Performance Bonus: {', '.join(eligible_employees)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb10494f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Query: 'Buy mobile phone buy phone online'\n",
      "-----------------------------------\n",
      "Keywords searched more than once:\n",
      "'buy': 2 times\n",
      "'phone': 2 times\n"
     ]
    }
   ],
   "source": [
    "#Problem Statement 2: Search Query Keyword Analysis\n",
    "\n",
    "import string\n",
    "\n",
    "# 1. Input search query\n",
    "query = \"Buy mobile phone buy phone online\"\n",
    "\n",
    "# 2. Convert to lower case and remove punctuation\n",
    "clean_query = query.lower()\n",
    "clean_query = clean_query.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# 3. Split into individual words (keywords)\n",
    "keywords = clean_query.split()\n",
    "\n",
    "# 4. Count the frequency of each keyword\n",
    "keyword_freq = {}\n",
    "for word in keywords:\n",
    "    keyword_freq[word] = keyword_freq.get(word, 0) + 1\n",
    "\n",
    "# 5. Display only keywords searched more than once\n",
    "print(f\"Original Query: '{query}'\")\n",
    "print(\"-\" * 35)\n",
    "print(\"Keywords searched more than once:\")\n",
    "\n",
    "for word, count in keyword_freq.items():\n",
    "    if count > 1:\n",
    "        print(f\"'{word}': {count} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc7045d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Readings: [3, 4, 7, 8, 10, 12, 5]\n",
      "-----------------------------------\n",
      "Valid Readings (Hour, Value):\n",
      "[(1, 4), (3, 8), (4, 10), (5, 12)]\n"
     ]
    }
   ],
   "source": [
    "#Problem Statement 3: Sensor Data Validation\n",
    "\n",
    "# 1. Input list of sensor readings\n",
    "sensor_readings = [3, 4, 7, 8, 10, 12, 5]\n",
    "\n",
    "# 2. Filter even readings and store with their hour index\n",
    "# We use enumerate() to get the index (hour) alongside the value\n",
    "valid_data = []\n",
    "\n",
    "for hour, reading in enumerate(sensor_readings):\n",
    "    if reading % 2 == 0:\n",
    "        valid_data.append((hour, reading))\n",
    "\n",
    "# 3. Display the results\n",
    "print(f\"Original Readings: {sensor_readings}\")\n",
    "print(\"-\" * 35)\n",
    "print(\"Valid Readings (Hour, Value):\")\n",
    "print(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce6060ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain          | Count  | Percentage\n",
      "-----------------------------------\n",
      "gmail.com       | 3      | 60.0%\n",
      "yahoo.com       | 2      | 40.0%\n"
     ]
    }
   ],
   "source": [
    "#Problem Statement 4: Email Domain Usage Analysis\n",
    "\n",
    "# 1. Input list of emails\n",
    "emails = [\n",
    "    \"ravi@gmail.com\",\n",
    "    \"anita@yahoo.com\",\n",
    "    \"kiran@gmail.com\",\n",
    "    \"suresh@gmail.com\",\n",
    "    \"meena@yahoo.com\"\n",
    "]\n",
    "\n",
    "# 2. Count users per domain\n",
    "domain_counts = {}\n",
    "for email in emails:\n",
    "    # Split the email at '@' and take the second part\n",
    "    domain = email.split('@')[1]\n",
    "    domain_counts[domain] = domain_counts.get(domain, 0) + 1\n",
    "\n",
    "# 3. Calculate and display percentage usage\n",
    "total_emails = len(emails)\n",
    "\n",
    "print(f\"{'Domain':<15} | {'Count':<6} | {'Percentage'}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for domain, count in domain_counts.items():\n",
    "    percentage = (count / total_emails) * 100\n",
    "    print(f\"{domain:<15} | {count:<6} | {percentage:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfd98102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily Average Sales: 1700.00\n",
      "Spike Threshold (Avg + 30%): 2210.00\n",
      "----------------------------------------\n",
      "Sales Spikes Detected:\n",
      "Day 6: 3000 (Spike!)\n"
     ]
    }
   ],
   "source": [
    "#Problem Statement 5: Sales Spike Detection\n",
    "\n",
    "# 1. Input list of daily sales\n",
    "sales = [1200, 1500, 900, 2200, 1400, 3000]\n",
    "\n",
    "# 2. Calculate daily average sales\n",
    "avg_sales = sum(sales) / len(sales)\n",
    "\n",
    "# 3. Define the threshold (30% above average)\n",
    "# Mathematically: average * 1.30\n",
    "threshold = avg_sales * 1.30\n",
    "\n",
    "# 4. Detect spikes (sales > threshold)\n",
    "print(f\"Daily Average Sales: {avg_sales:.2f}\")\n",
    "print(f\"Spike Threshold (Avg + 30%): {threshold:.2f}\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Sales Spikes Detected:\")\n",
    "\n",
    "for day, value in enumerate(sales, start=1):\n",
    "    if value > threshold:\n",
    "        print(f\"Day {day}: {value} (Spike!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdcef0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate User IDs detected:\n",
      "------------------------------\n",
      "ID: user1 | Appearances: 3\n",
      "ID: user3 | Appearances: 2\n"
     ]
    }
   ],
   "source": [
    "#Problem Statement 6: Duplicate User ID Detection\n",
    "\n",
    "# 1. Input list of user IDs\n",
    "user_ids = [\"user1\", \"user2\", \"user1\", \"user3\", \"user1\", \"user3\"]\n",
    "\n",
    "# 2. Count the frequency of each user ID\n",
    "id_counts = {}\n",
    "for uid in user_ids:\n",
    "    id_counts[uid] = id_counts.get(uid, 0) + 1\n",
    "\n",
    "# 3. Identify and display duplicates\n",
    "print(\"Duplicate User IDs detected:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "has_duplicates = False\n",
    "for uid, count in id_counts.items():\n",
    "    if count > 1:\n",
    "        print(f\"ID: {uid} | Appearances: {count}\")\n",
    "        has_duplicates = True\n",
    "\n",
    "if not has_duplicates:\n",
    "    print(\"No duplicates found. All User IDs are unique.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
